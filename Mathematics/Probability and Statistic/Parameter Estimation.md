# 说明
我用这篇文档梳理一些重要概念，还有背后的统计观念。
# 问题的整体理解
* 估计的对象是谁？
  * 一个随机变量，已知概率分布的类型，估计概率分布的参数
  * 也可以不讨论概率分布的类型，只是估计数字特征
    * 均值
    * 方差
* 估计的已知信息是什么？
  * 一个随机变量的多次具体取值，也就是样本值
# 最大似然估计
## 方法的使用场景
* 已知概率分布的类型
  * 二项分布
  * 正态分布
  * 指数分布
  * Poisson分布
  * 等等
* 未知概率分布的参数
  * 彻底地不知道
  * 在几个选项中未知
* “确定”（估计）参数的思路
  * 既然以及观测到了结果（各个样本值）
  * 那就调整参数
  * 直到以及发生的现象（样本），在原有模型（已知的概率分布类型）下，概率值达到最大（最大似然的含义）
## 操作办法
* 构造似然函数

$$
L_n(x_1,...x_n;\theta _1,...,\theta _m)=\prod_{i=1}^n p(x_i;\theta _1,...,\theta _m)
$$

>这里需要辨析几个概念：
>* 如果把 $\theta _1,...,\theta _m$ 取定，把 $x_1,...x_n$ 视作随机变量。那么，似然函数对应一个联合分布的概率密度。
>   * 这种观点是假说演绎思维下的观点
>   * 一般情况下，估计量 $g(x_1,...x_n;\theta _1,...,\theta _m)$ 也采用这种观点
>       * 但这和似然函数没有什么关系
>       * 只是参变量选取的看法上相一致，都认为概率分布参数确定，样本未定。把它看作是样本的函数。
>       * 似然函数并不是一个估计量
>* 如果把  $x_1,...x_n$ 作为样本值取定，把 $\theta _1,...,\theta _m$ 视作待定的、需要调整的参数，允许其变动。那么，似然函数是参数的函数。
>   * 这种观点才是似然函数的准确含义
>   * 似然函数是参数的函数
>   * 而样本值对于似然函数是取定的参量
  

* 似然函数求极值（最大值点），转化为求解似然方程组
  * 似然函数是参数的函数
  * 求极值（最大值点），只需要让各个偏导数为零
    * 当然要验证Hessian矩阵的负定性
  
# 矩估计
## 方法的使用场景
* 已知概率分布的类型
* 未知概率分布的参数
* 估计参数的思路
  * 给定参数，可以求出各阶矩
  * 估计出各阶矩，也就估计出了参数
  * 从而将参数的估计，转化为了各阶矩的估计
  * 而各阶矩采取简单的，大数定律下，满足相合性的估计
## 操作办法

$$
\text{Ex}(X^k)
$$

的估计量选取为

$$
\frac{1}{n}\sum_{i=1}^n x_i^k
$$

然后用估计出来的各阶矩，表达出来待定参数（求解方程组）

一般来说，未知参数的个数，等于需要估计的矩的最高阶数。
原点矩也可以改用中心距。

# 期望与方差的点估计
## 方法的使用场景
* 不关心具体的概率分布类型（不受限于概率分布类型）
* 只关心期望值和方差
## 操作办法
* 计算样本均值
* 计算样本方差
* 注意，这两个估计量都满足“无偏性”
# 辨析
关于点估计，课本介绍了三种方法：
* 最大似然估计法
* 矩估计法
* 期望与方差的“最小方差无偏估计量”

需要注意的是，对于同一个量的估计，采用的方法不同，结果也可能不同。

* 均匀分布，区间端点的估计
  * 最大似然估计，取样本的最大值和最小值
  * 矩估计，则不一样
* 正态分布
  * 最大似然估计和矩估计的方法一样
  * 但是方差的估计，并不是无偏估计量

补充说明一点
* 估计量的无偏性，指的是估计量作为随机变量（样本值未定的情形），期望值和待估计参数相等
* 估计量的最小方差，保证了估计量作为随机变量（样本值未定的情形）
  * 它的分布将会紧紧围绕期望值集中分布
  * 并且样本数量越大，分布集中程度越大（偏离的概率越小）
* 最小方差无偏估计量保证了
  * 一则无偏
  * 二则有效
    * 指的是随着样本量增大，越来越精确（有效），直到完全一致（无偏）

那么哪种方法最优呢？
* 说最小无偏估计量是最优的估计量
* 与此同时，也说最大似然估计是最优的
* 这两种“最优”的标准是不一样的
  * 这从它们的求解和构造过程就可以看出来了
* 矩估计，怎么样都不是最优的，但却常常是最方便的。

